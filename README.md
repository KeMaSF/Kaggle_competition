# Kaggle_competition
This repo explain the LLM competition (https://www.kaggle.com/competitions/llms-you-cant-please-them-all). First we introduce the goal of this competition then we introduce the method, which consists of optimization step and LLM prompt step.
## Goal
There are three unknown LLM judges, we need to generate 3 essays such that the score generated by the judges is maximized.

The score is calculated as follows:

![alt text](https://github.com/KeMaSF/Kaggle_competition/blob/main/equation.png) 

avg_h: the variance between the scores returned by the 3 judges for a single essay;

min_v: the variance between the scores returned by a single judge across every essay;

avg_e: English language confidence scores;

avg_s: sequence similarity scores;

avg_q: an average of three quality scores for every essay;

The following image shows the topic of essays, which is stored in a csv file:

![alt text](https://github.com/KeMaSF/Kaggle_competition/blob/main/data.png) 

## Step1. Optimization Problem
Accordingly, the score for a single essay can be calcualted as follows:

![alt text](https://github.com/KeMaSF/Kaggle_competition/blob/main/single_score.jpg) 

Suppose the scores given by three LLM judges for a single essay are $q_1, q_2, q_3$, then we have:

avg_q = mean($q_1, q_2, q_3$)

avg_h = var($q_1, q_2, q_3$)

We can ignore avg_e and avg_s as long as we are using English in our generated essay and we do not repeat sentences then we should be good. Then to maximize the score of a single essay we need to solve the following problem:

![alt text](https://github.com/KeMaSF/Kaggle_competition/blob/main/Optimization.jpg) 

To solve this problem, we resort to the "scipy" library, details are shown in the "optimization.py" file. After solving this optimization problem, we can see to maximize the score for a single essay, the score has to be 9, 9, 0. 

## Step 2: LLM Prompt



Used most commonly used English words from https://www.kaggle.com/datasets/jiprud/words-en. 

